# Masked-Language-Modeling-NLP
This project contains  a Visualizes Transformer self-attention and predicts masked words using BERT for NLP tasks. And demonstrates attention heatmaps for every layer and head.
